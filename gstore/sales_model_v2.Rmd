---
title: "GStore Predictor"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5, dpi = 240)
options(warn=-1)

library(gbm)
library(data.table)
library(plyr)
library(stringi)
library(stringr)
library(ggplot2)
library(gridExtra)
library(zip)
library(xgboost)
library(corrplot)
library(forcats)
#library(pdp)
library(e1071)
library(jsonlite)
library(lubridate)

#library(rjson)
#library(caret)

#working_folder = 'C:/Dev/Kaggle/'
working_folder = file.path(Sys.getenv("HOME"), 'source/github/KaggleSandbox/')


source(file.path(working_folder, '/Utils/common.R'))
```

## Loan Data

```{r load_data}

df_filename = file.path(working_folder,'gstore/data/all.rds')


if(file.exists(df_filename)) {
  print(sprintf('reading: %s', df_filename))
  df = readRDS(df_filename)
}else {
  
  df_train = fread(file.path(working_folder,'gstore/data/train.csv'), check.names=T)#, nrows = 10000)
  df_test  = fread(file.path(working_folder,'gstore/data/test.csv'),  check.names=T)#, nrows = 10000)
  
  df_train[,is_train:=T ]
  df_test[, is_train:=F ]
  
  df = rbind(df_train, df_test)
  train_index = df$is_train
  
  #json column:fields 
  # device: browser, operatingSystem, isMobile, deviceCategory
  # geoNetwork: continent, subContinent, country, region, metro, networkDomain
  # totals:  visits, hits, pageviews, bounces, newVisits
  # trafficSource
  
  # TODO: try to think of a better way to do this
  parse_json <- function(json_str, fields){
    values = fromJSON(stri_replace_all_fixed(json_str, '\"\"','\"') )[fields]
    names(values) <-fields
    #values[sapply(values , is.null)] = 'NA'
    values = lapply(values, as.character)
    #print(sapply(values , class))
    return(values)
  }
  parse_json_all <- function(json_str){
    values = fromJSON(stri_replace_all_fixed(json_str, '\"\"','\"') )
    return(values)
  }
  #parse_geo_v <- Vectorize(parse_geo, SIMPLIFY = TRUE)
  
  geo_fields = c('continent', 'subContinent', 'country', 'region', 'metro', 'city', 'networkDomain')
  device_fields = c('browser', 'operatingSystem', 'isMobile', 'deviceCategory')
  trafficSource_fields = c('campaign', 'source', 'medium', 'keyword',
                           'isTrueDirect','adContent',
                           'adwordsClickInfo.page','adwordsClickInfo.slot','adwordsClickInfo.gclId','adwordsClickInfo.adNetworkType','adwordsClickInfo.isVideoAd','referralPath')
  totals_fields = c('visits', 'hits', 'pageviews','bounces', 'newVisits', 'transactionRevenue')
  
  geo_columns           = stri_join('geo_', geo_fields)
  device_columns        = stri_join('device_', device_fields)
  trafficSource_columns = stri_join('trafficSource_', trafficSource_fields)
  totals_columns        = stri_join('totals_', totals_fields)
  
  all_rows = seq_len(nrow(df))
  
  df[, (geo_columns)          := parse_json(geoNetwork, geo_fields),               by = all_rows]
  df[, (device_columns)       := parse_json(device, device_fields),                by = all_rows]
  df[, (trafficSource_columns):= parse_json(trafficSource, trafficSource_fields),  by = all_rows]
  df[, (totals_columns)       := parse_json(totals, totals_fields),                by = all_rows]
  
  df[,geoNetwork:=NULL]
  df[,device:=NULL]
  df[,trafficSource:=NULL]
  df[,totals:=NULL]
  
  bool_columns = c('device_isMobile','trafficSource_isTrueDirect')
  df[, (bool_columns):=lapply(.SD, as.logical), .SDcols = bool_columns]
  
  num_columns = c('totals_hits','totals_pageviews', 'totals_bounces', 'totals_newVisits','totals_transactionRevenue','totals_visits')
  df[, (num_columns):=lapply(.SD, as.numeric), .SDcols = num_columns]

  
  #parse_json(df$device[4],device_fields)
  #parse_json(df$trafficSource[4],trafficSource_fields)
  #parse_json(df$trafficSource[5],trafficSource_fields)
  #df[,geo_columns, with = F]
  #df[,device_columns, with = F]
  #df[,trafficSource_columns, with = F]
  #df[,totals_columns, with = F]
  
  #check forpossible values
  #temp = ldply(sample.int(nrow(df), 10000), function(i) {
  #   res = data.table(t(unlist(parse_json_all(df$trafficSource[i]))))  
  #   return (res)
  #} )
  #str(temp)
  #sapply(temp, function(x) length(unique(x)))
  
  
  #a = df[, .(geoNetwork, geo_continent)]
  #a = df[, .(device, device_isMobile)]
  #a = df[, .(trafficSource, trafficSource_isTrueDirect)]
  #df[, .(trafficSource, trafficSource_isTrueDirect)]
  
  saveRDS(df, df_filename)
}

id_columns = c('fullVisitorId','sessionId','visitId')

df[, iso_date := as.Date(as.character(date), format = '%Y%m%d')]
df[, date_month := month(iso_date)]
df[, date_year := year(iso_date)]
df[, date_day := day(iso_date)]
df[, date_wday := weekdays(iso_date)]

df[, revenue := totals_transactionRevenue]
df[is.na(revenue), revenue := 0]

df[, revenue_log := log(1+revenue)]
df[, is_revenue := as.numeric(revenue>0)]

#df[,trafficSource_isTrueDirect := as.numeric(is.na(trafficSource_isTrueDirect))]

df[, c("geo_networkDomain_level1", "geo_networkDomain_level2", "geo_networkDomain_level3") := tstrsplit(as.character(geo_networkDomain), ".", fixed=TRUE)]
df[, geo_networkDomain_levels:= str_count(as.character(geo_networkDomain), fixed("."))]

#combine levels
combine_levels <- function(x, n = 3000){
  counts = table(x)
  keep_levels = names(counts)[which(counts > n)]
  return( fct_other(x,keep = keep_levels) )
}
cumsum_resets <-function(x, resets = is.na(x)){
  return ( ave(x, rev(cumsum(rev(resets))), FUN = cumsum))
}

columns_with_many_levels = names(which(sapply(df, function(x) length(levels(x))) >= 256)) #technically max is 1024 
columns_with_many_levels_major = stri_join(columns_with_many_levels, '_major')

df[, (columns_with_many_levels_major):=lapply(.SD, function(x) combine_levels(x, 1000) ), .SDcols = columns_with_many_levels]

#convert types
char_columns = names(which(lapply(df, is.character) ==T)) %!in_set% id_columns
df[, (char_columns):=lapply(.SD, as.factor), .SDcols = char_columns]

bool_columns = names(which(lapply(df, is.logical) ==T)) %!in_set% id_columns
df[, (bool_columns):=lapply(.SD, as.numeric), .SDcols = bool_columns]

na_columns = names(which(lapply(df, function(x) length(x) == sum(is.na(x))  ) ==T)) %!in_set% id_columns
df[, (na_columns):=NULL]


#add historical variables

df[order(visitStartTime),prev_iso_date:=shift(iso_date), by = .(fullVisitorId)]
df[order(visitStartTime),prev_visitId:=shift(visitId), by = .(fullVisitorId)]
df[,days_since_last_visit:=as.numeric(iso_date - prev_iso_date)]

df[order(visitNumber),cum_revenue:=cumsum(revenue)-revenue, by = .(fullVisitorId)]
df[order(visitNumber),cum_pageviews:=cumsum(totals_pageviews), by = .(fullVisitorId)]
df[order(visitNumber),max_pageviews:=cummax(totals_pageviews), by = .(fullVisitorId)]
df[order(visitNumber),cum_sales:=cumsum(is_revenue)-is_revenue, by = .(fullVisitorId)]
df[,avg_pageviews:=cum_pageviews/visitNumber]

df[,cum_pageviews_log:=log(1+cum_pageviews)]
df[,cum_revenue_log:=log(1+cum_revenue)]
df[,totals_pageviews_log:=log(1+totals_pageviews)]
df[,totals_hits_log:=log(1+totals_hits)]

#df[order(visitNumber),visits_since_last_sale:=cumsum_resets(1-is_revenue, is_revenue), by = .(fullVisitorId)]

df[fullVisitorId == '9771437221362506189',.(iso_date, prev_iso_date, visitId, prev_visitId, visitNumber, visitStartTime, totals_hits, totals_pageviews, revenue, cum_revenue, cum_sales, avg_pageviews, days_since_last_visit)][order(visitNumber),]

df[,is_train :=as.logical(is_train)]

table(df$is_revenue)
table(df$geo_country)
```


## View Data

```{r view_data}

#cor(df_agg[,.(totals_pageviews_max_log-totals_pageviews_log, totals_pageviews_log)], use = 'pairwise.complete.obs')
```

## Logistic PD model 
                                                              var    rel.inf
totals_pageviews_log                         totals_pageviews_log 55.6983213
geo_country                                           geo_country 13.4292868
cum_pageviews_log                               cum_pageviews_log  7.0716408
geo_city_major                                     geo_city_major  5.2969176
cum_revenue_log                                   cum_revenue_log  2.6811241
totals_hits                                           totals_hits  2.5472390
trafficSource_source_major             trafficSource_source_major  2.4035361
days_since_last_visit                       days_since_last_visit  2.2459888
device_operatingSystem                     device_operatingSystem  1.8421394
date_month                                             date_month  1.7388381
trafficSource_referralPath_major trafficSource_referralPath_major  1.1839111
geo_networkDomain_level1_major     geo_networkDomain_level1_major  1.0373205
geo_networkDomain_major                   geo_networkDomain_major  0.7162055
max_pageviews                                       max_pageviews  0.5029983
cum_sales                                               cum_sales  0.4422662
visitNumber                                           visitNumber  0.3746568
geo_metro                                               geo_metro  0.1996965
geo_region_major                                 geo_region_major  0.1415445
device_deviceCategory                       device_deviceCategory  0.1335105
avg_pageviews                                       avg_pageviews  0.1174594
```{r pd_predict_model}
tindex = df$is_train

obj_var = 'is_revenue'
actual.pd = df[[obj_var]]

#only keep several car_11 levels
exclude_vars = c(id_columns, columns_with_many_levels,'prev_visitId','visitStartTime','prev_iso_date','is_train','iso_date', 'date',
                 'totals_transactionRevenue','revenue','revenue_log','prev_visit_number', obj_var,#id and outcome var 
                 'cum_pageviews','totals_pageviews','cum_revenue','totals_hits') #replaced with logs

all_vars = names(df) %!in_set% c(exclude_vars)

set.seed(1012356)

formula.pd = formula(stri_join( obj_var, ' ~ ', stri_join(unique(all_vars), collapse = ' + ')))

model_vars = all.vars(formula.pd) %!in_set% c(obj_var)
var.monotone = rep(0, length(model_vars))

#df[1:10, ..model_vars]
#str(df[, ..model_vars])

#num_vars  = model_vars %in_set% names(which(sapply(df, is.numeric)))
#corr_matrix = cor(df[, ..num_vars ], use="complete.obs")
#corrplot(corr_matrix, method="number", number.cex = 0.5)
#corrplot(corr_matrix, method="circle", order="hclust")

mon_inc_vars = c('totals_pageviews_log')
mon_dec_vars = c()

var.monotone[model_vars %in% mon_inc_vars]  =  1
var.monotone[model_vars %in% mon_dec_vars]  = -1

cv_folds = 0
max_it = 3000

model.pd  = gbm(formula.pd,
                 distribution = "bernoulli",
                 n.trees = max_it,
                 cv.folds = cv_folds,
                 shrinkage = 0.01,
                 interaction.depth=6,
                 train.fraction = 0.7,
                 bag.fraction = 0.9,# 0.5 for small samples, 0.7 for large
                 n.cores = 2,
                 var.monotone = var.monotone,
                 data = df[tindex , all.vars(formula.pd), with = F],
                 verbose = TRUE)

#saveRDS(model.pd, file.path(working_folder,'gstore/model_pd.v2.rds'))
#model.pd = readRDS(file.path(working_folder,'gstore/model_pd.rds'))

plot_gbmiterations(model.pd) #0.03795, AUC

best_it.pd = gbm.perf(model.pd, plot.it = F) #ifelse(cv_folds==0, max_it, gbm.perf(model.pd, plot.it = F))

pred.pd  = predict(model.pd, n.trees = best_it.pd, newdata = df, type = 'response')
plot_binmodel_roc(actual.pd[tindex], pred.pd[tindex])
plot_binmodel_cdf(actual.pd[tindex], pred.pd[tindex])
plot_binmodel_percentiles(actual.pd[tindex], pred.pd[tindex], 100)
gbm.roc.area(actual.pd[tindex], pred.pd[tindex]) #0.9910346

#summary(glm('actual.pd ~ model ', data = data.frame(actual.pd = actual.pd[tindex], model = pred.gbm[tindex]), family = binomial(link = "logit"))) 

#influence
var_inf = summary(model.pd, n.trees = best_it.pd, plotit = F)
var_inf = subset(var_inf, rel.inf>0.1)
#fwrite(var_inf, file = file.path(working_folder, "gstore/variables.csv"), row.names = FALSE)
plot_gbminfluence(var_inf)
print(var_inf)

imp_vars = as.character(var_inf$var[var_inf$rel.inf>0.1])
#df_agg[1:100,..imp_vars]

plots = plot_gbmpartial(model.pd, best_it.pd, imp_vars, output_type = 'response')
marrangeGrob(plots, nrow = 3, ncol = 4, top = NULL)

plots = llply(all.vars(formula.pd), function(var_name) {
  p = plot_profile(pred.pd[tindex], actual.pd[tindex],df[[var_name]][tindex], error_band = 'binom') +
    ggtitle(var_name) +  theme(title =element_text(size=6))
  return( p )
})
marrangeGrob(plots, nrow = 5, ncol = 7, top = NULL)

#all vars
plots = llply(names(df_agg) %!in_set% c('fullVisitorId', all.vars(formula.pd)), function(var_name) {
  #print(var_name)
  p = plot_profile(pred.pd[tindex], actual.pd[tindex],df_agg[[var_name]][tindex], error_band = 'binom') +
    ggtitle(var_name) +  theme(title =element_text(size=6))
  return( p )
})
marrangeGrob(plots, nrow = 6, ncol = 6, top = NULL)

plot_profile(pred.pd[tindex], actual.pd[tindex],df$totals_bounces[tindex], error_band = 'binom')
plot_profile(pred.pd[tindex], actual.pd[tindex],df$date_m8_pct[tindex], error_band = 'binom')
plot_profile(pred.pd[tindex], actual.pd[tindex],df$date_m4_pct_pos[tindex], error_band = 'binom')
plot_profile(pred.pd[tindex], actual.pd[tindex],df$date_m5_pct_pos[tindex], error_band = 'binom')

plot_profile(pred.pd[tindex], actual.pd[tindex],fct_reorder(df$geo_country[tindex],actual.pd[tindex], sum), error_band = 'binom')

```


### Revenue Model,  rgs - revenue given sale 

cv-10: 1.10421
  var    rel.inf
cum_pageviews_log                               cum_pageviews_log 24.5383743
cum_revenue_log                                   cum_revenue_log 13.4685020
totals_hits                                           totals_hits 12.1477114
geo_city_major                                     geo_city_major 11.5661763
device_operatingSystem                     device_operatingSystem  7.2685218
trafficSource_source_major             trafficSource_source_major  5.6850321
max_pageviews                                       max_pageviews  4.8609675
geo_networkDomain_level1_major     geo_networkDomain_level1_major  4.2805248
geo_country                                           geo_country  2.4069893
date_wday                                               date_wday  2.0517012
days_since_last_visit                       days_since_last_visit  1.8944515
device_browser                                     device_browser  1.7842020
geo_networkDomain_major                   geo_networkDomain_major  1.4026849
cum_sales                                               cum_sales  1.0302711
avg_pageviews                                       avg_pageviews  0.9415283
device_deviceCategory                       device_deviceCategory  0.7899413
geo_networkDomain_level2_major     geo_networkDomain_level2_major  0.6343835
totals_pageviews_log                         totals_pageviews_log  0.5806981
visitNumber                                           visitNumber  0.4645488
channelGrouping                                   channelGrouping  0.4237241
geo_metro                                               geo_metro  0.3987167
geo_region_major                                 geo_region_major  0.3412164
date_month                                             date_month  0.3286039
trafficSource_keyword_major           trafficSource_keyword_major  0.2533238
trafficSource_referralPath_major trafficSource_referralPath_major  0.2207317
```{r revenue_predict_model, eval = FALSE}

actual.rgs = df$revenue

tindex_rgs = tindex & df$is_revenue

set.seed(1012356)

rgs_vars = names(df) %!in_set% c(exclude_vars,'totals_bounces') # use all vars

formula.rgs = formula(stri_join( 'revenue_log ~ ', stri_join(unique(rgs_vars),collapse = ' + ')))

model_vars = all.vars(formula.rgs) %!in_set% c('revenue_log')
var.monotone = rep(0, length(model_vars))

mon_inc_vars = c()
mon_dec_vars = c()

var.monotone[model_vars %in% mon_inc_vars]  =  1
var.monotone[model_vars %in% mon_dec_vars]  = -1

cv_folds = 3
max_it = 2000
#0.49
model.rgs  = gbm(formula.rgs,
                 distribution = "gaussian",
                 n.trees = max_it,
                 cv.folds = cv_folds,
                 shrinkage = 0.01,
                 interaction.depth=7,
                 train.fraction = 1.0,
                 bag.fraction = 0.8,# 0.5 for small samples, 0.7 for large
                 n.cores = 4,
                 var.monotone = var.monotone,
                 data = df[tindex_rgs , all.vars(formula.rgs), with = F],
                 verbose = FALSE)

#saveRDS(model.rgs, file.path(working_folder,'gstore/model_rgs.rds'))
#model.rgs = readRDS(file.path(working_folder,'gstore/model_rgs.rds'))

plot_gbmiterations(model.rgs) # 1.09609

best_it.rgs = gbm.perf(model.rgs, plot.it = F) #ifelse(cv_folds==0, max_it, gbm.perf(model.rgs, plot.it = F))

#influence
var_inf = summary(model.rgs, n.trees = best_it.rgs, plotit = F)
var_inf = subset(var_inf, rel.inf>0.1)
#fwrite(var_inf, file = file.path(working_folder, "gstore/variables.csv"), row.names = FALSE)
plot_gbminfluence(var_inf)
print(var_inf)

imp_vars = as.character(var_inf$var[var_inf$rel.inf>0.5])
#df_agg[1:100,..imp_vars]

plots = plot_gbmpartial(model.rgs, best_it.rgs, imp_vars, output_type = 'link')
marrangeGrob(plots, nrow = 3, ncol = 3, top = NULL)

#var_interaction = gbm_interactions(model.rgs, df_agg[tindex_rgs,], iter = best_it.rgs, min_influence = 1, degree = 2) 
#plot_gbminteractions(subset(var_interaction, interaction_score>0.1))
#print(var_interaction)

#plots = plot_gbmpartial_2d(model.rgs, best_it.rgs, as.character(subset(var_interaction,interaction_score>0.1)$vars), output_type = 'link')
#marrangeGrob(plots, nrow = 2, ncol = 2, top = NULL)


pred.rgs = predict(model.rgs, n.trees = best_it.rgs, newdata = df)
pred.rev = pred.rgs * pred.pd
summary(lm('actual ~ model', data.frame(actual = df$revenue_log[tindex],     model = pred.rev[tindex]))) #0.4758
summary(lm('actual ~ model', data.frame(actual = df$revenue_log[tindex_rgs], model = pred.rgs[tindex_rgs]))) #0.4161
ggplot(data.frame(actual = df$revenue_log[tindex_rgs], model = pred.rgs[tindex_rgs]), aes(model, actual)) + geom_point() + geom_abline(slope = 1, color = 'red')

#all vars
plots = llply(all.vars(formula.rgs), function(var_name) {
  p = plot_profile(pred.rgs[tindex_rgs], actual.rgs [tindex_rgs], df[[var_name]][tindex_rgs], error_band = 'normal') +
    ggtitle(var_name) +  theme(title =element_text(size=6))
  return( p )
})
marrangeGrob(plots, nrow = 6, ncol = 7, top = NULL)


plot_profile(pred.rgs[tindex_rgs], actual.rgs [tindex_rgs],df_agg$geo_city[tindex_rgs], error_band = 'normal')
plot_profile(pred.rgs[tindex_rgs], actual.rgs [tindex_rgs],df_agg$geo_networkDomain_level1[tindex_rgs], error_band = 'normal')

plot_profile(pred.rgs[tindex_rgs], df_agg$revenue[tindex_rgs],df_agg$totals_bounces[tindex_rgs], error_band = 'normal', bucket_count = 20)

#revenue
plot_profile(pred.rev[tindex], df_agg$revenue[tindex],df_agg$device_operatingSystem_major[tindex], error_band = 'normal')


table(df_agg[is_revenue == T, .(is_train, first_month)])
```

## Save Results
1.4476 - best
1.4488 - latest

```{r save_results}

df_s = df[, .(fullVisitorId, is_train, totals_transactionRevenue)]
df_s[, expected_revenue := (exp(pred.rgs)-1.0) * pred.pd ]
df_s[, sale_prob := pred.pd ]

df_test = df_s[is_train==TRUE, .(PredictedLogRevenue = log(1  + sum(expected_revenue, na.rm = T)),  ActualLogRevenue=log(1  + sum(totals_transactionRevenue, na.rm = T))), by = .(fullVisitorId)]

summary(lm('ActualLogRevenue ~ PredictedLogRevenue', df_test))

submit = df_s[is_train==FALSE, .(PredictedLogRevenue = log(1  + sum(expected_revenue, na.rm = T))), by = .(fullVisitorId)]

file = file.path(working_folder, "gstore/solution.v2.csv")
  
fwrite(submit, file = file, row.names = FALSE)

zip(paste(file, '.zip', sep = ''), file)
  
print(file)

#fullVisitorId,PredictedLogRevenue

```