---
title: "Optimization Primer"
output: html_document
date: '2022-10-13'
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rBayesianOptimization)
library(dfoptim)
library(pso)
library(optimx)
library(DEoptim)

# YMMV, MLSL
library(nloptr)

```

## 1D

```{r opt_1d}

objective_1d <- function(x){  -exp(-(x - 2)^2) }

Test_Fun <- function(x) {
  list(Score = -objective_1d(x),   Pred = 0)
}
####  BayesianOptimization --------
#### Round = 14	x = 1.99999	Value = -9.058776e-11 
OPT_Res <- BayesianOptimization(Test_Fun,
                                bounds = list(x = c(1, 3)),
                                init_points = 3, n_iter = 20,
                                verbose = TRUE)


optimize(objective_1d, c(-6, 6), maximum = FALSE) #2.000866

opt_control = list(trace = 2)
res = optim(c(3), objective_1d, method = 'BFGS', control = opt_control)
res = optim(c(3), objective_1d, method = 'L-BFGS-B', control = opt_control)
res = optim(c(3), objective_1d, method = "CG", control = opt_control)
res = optim(c(3), objective_1d, method = "SANN", control = opt_control)
res = optim(c(3), objective_1d, method = "Brent", lower = -6, upper = 6, control = opt_control) #same as optimize
```


## 2D

```{r opt_2d}
#typical initial value (2,2), (5,5)
objective_2d <- function(x){  (1 - x[1])^2 + 100 * (x[2] - x[1] * x[1])^2  } # solution is c(1, 1)

####  BayesianOptimization --------
#Round = 20	x = -0.03818981	y = -0.04093246	Value = -1.257537 
OPT_Res <- BayesianOptimization(function(...){ x = as.numeric(list(...)); list(Score = -objective_2d(x),   Pred = 0)},
                                bounds = list(x = c(-5, 5), y = c(-5, 5)),
                                init_points = 20, n_iter = 10,
                                verbose = TRUE)


opt_control = list(trace = 2, maxit = 10000)
init_params = c(0, 10)
res = optim(init_params, objective_2d, method = 'BFGS', control = opt_control)
res = optim(init_params, objective_2d, method = 'L-BFGS-B', control = opt_control)
res = optim(init_params, objective_2d, method = "CG", control = opt_control)
res = optim(init_params, objective_2d, method = "SANN", control = opt_control)
res = optim(init_params, objective_2d, method = "Nelder-Mead", control = opt_control)

res = hjk(init_params, objective_2d, control = list(info = TRUE))
res = mads(init_params, objective_2d,  lower=-10, upper=10, control = list(trace = FALSE)) #too many evaluations
res = nmk(init_params, objective_2d, control = list(trace = TRUE))
res = nmkb(init_params, objective_2d, lower=-10, upper=10, control = list(trace = TRUE)) #does not work

res = psoptim(init_params,objective_2d,lower=-10,upper=10,control=list(abstol=1e-8))

optimx(init_params, objective_2d, control = list(all.methods = TRUE))
res = optimx(init_params, objective_2d, method = "Nelder-Mead")

DEoptim(objective_2d, c(-10, -10), c(10, 10))
```

## n-D

```{r opt_Nd}
objective_nd <- function(x){
  n <- length(x)
  sum (100*(x[1:(n-1)]^2 - x[2:n])^2 + (x[1:(n-1)] - 1)^2)
}

init_params <- rep(5, 10)

hjk(init_params, objective_nd)
nmk(init_params, objective_nd)
#mads(init_params, objective_nd)
optim(init_params, objective_nd, method = "Nelder-Mead", control = opt_control)
optim(init_params, objective_nd, method = 'BFGS', control = opt_control)
optim(init_params, objective_nd, method = "CG", control = opt_control)

psoptim(init_params,objective_nd,lower=-10,upper=10,control=list(abstol=1e-8))

optimx(init_params, objective_nd, control = list(all.methods = TRUE))
res = optimx(init_params, objective_nd, method = "Nelder-Mead")

res = DEoptim(objective_nd, rep(-10, length(init_params)), rep(10, length(init_params)), DEoptim.control(itermax = 1000, trace = FALSE))

#https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/
#res <- nloptr( x0=init_params, eval_f=objective_nd, eval_grad_f=NULL, opts = list("algorithm"="NLOPT_GD_STOGO_RAND", "xtol_rel"=1.0e-8))


### A non-smooth problem from Hock & Schittkowski #78
hs78 <- function(x){
f <- rep(NA, 3)
f[1] <- sum(x^2) - 10
f[2] <- x[2]*x[3] - 5*x[4]*x[5]
f[3] <- x[1]^3 + x[2]^3 + 1
F <- prod(x) + 10*sum(abs(f))
return(F)
}
p0 <- c(-2,1.5,2,-1,-1)
ans2 <- mads(p0, hs78, control=list(trace=FALSE)) #minimum value around -2.81
```
