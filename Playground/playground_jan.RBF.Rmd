---
title: 'Kaggle Playground: Feb 2020'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(stringi)
#library(gbm)
library(ggplot2)
library(gridExtra)
#library(dplyr)
library(plyr)
library(corrplot)
#library(xgboost)
#library(zip)
#library(caret)
#library(lightgbm)
library(forcats)
library(proxy)
library(MASS)
#library(rBayesianOptimization)
#library(tune) #https://datascienceplus.com/grid-search-and-bayesian-hyperparameter-optimization-using-tune-and-caret-packages/


working_folder = 'D:/Github/KaggleSandbox'
#working_folder = file.path(Sys.getenv("HOME"), 'source/github/KaggleSandbox/')

source(file.path(working_folder, 'Utils/common.R'))

rmsqr <-function(actual, model) {
  sqrt( mean( (actual - model) * (actual - model) ) )
}

```

## Load Data

```{r load_data}
load_existing = FALSE

if (load_existing) {
  df <- fread(file.path(working_folder,'Playground/Jan2021/data/df.csv'), check.names = TRUE)
  
} else{
  train <- fread(file.path(working_folder,'Playground/Jan2021/data/train.csv'), check.names = TRUE)
  test  <- fread(file.path(working_folder,'Playground/Jan2021/data/test.csv'),  check.names = TRUE) # 1459   80
  test[, target:=NA]
  df = rbind(train, test)
  
  gc(reset=TRUE)
}

test_index = is.na(df$target)
train_index = !test_index

obj_var = 'target'
all_vars = names(df) %!in_set% c('id', obj_var) #14 variables
all_vars = all_vars[grep('^(cont|cat)', all_vars)]

plot_profiles <-function(model, data)
{
    plots = llply(all_vars, function(var_name) {
    p = plot_profile(model,  data[['target']], data[[var_name]], bucket_count = 20, error_band = 'norm') +
      ggtitle(var_name) +  theme(title =element_text(size=6))
    return( ggplotGrob(p) )
  })
  marrangeGrob(plots, nrow = 5, ncol = 5, top = NULL)
}

```
##Plot Data

```{r plot_data}

cor_mat = cor(data.matrix(df[train_index,c('target', all_vars), with = FALSE]), use = 'pairwise.complete.obs')
corrplot(cor_mat, method="number", number.cex = 0.8, number.digits = 2,  order="hclust")
corrplot(cor_mat, method="circle", number.cex = 0.5, order="hclust")

p_index = sample(which(train_index), 10000 )
ggplot(df[p_index], aes(id, target)) + geom_point()

ggplot(df[p_index], aes(cont8, target)) + geom_point() + geom_smooth()
ggplot(df[p_index], aes(cont3, target)) + geom_point() + geom_smooth()

#check sample
s_index = sample.int(nrow(df), nrow(df))
plots = llply(all_vars, function(var_name){
  ggplot(df[s_index ], aes_string(var_name, group = 'is.na(target)', color = 'is.na(target)')) + geom_density(adjust = 0.1) + ggtitle(var_name)
  })
marrangeGrob(plots, nrow = 5, ncol = 5, top = NULL)

var_pairs = data.frame(t(combn(all_vars, 2, simplify = TRUE)))
plots = llply(seq(nrow(var_pairs)), function(i) { 
   ggplot(df[p_index ], aes_string(var_pairs$X1[i], var_pairs$X2[i])) + geom_point(alpha = 0.5)
  })
marrangeGrob(plots, nrow = 5, ncol = 5, top = NULL)
#ggplot(melt(data.table(cor_mat)), aes(Var1, Var2, fill = value)) + geom_tile()

#check correlations

combn(as.character(all_vars), 2, simplify = TRUE)
all_comb = data.table(expand.grid(all_vars, all_vars, all_vars, all_vars))
#all_comb = all_comb[Var1 != Var2]

res = ldply(seq(nrow(all_comb)), function(i) { 
  a1 = df[[all_comb$Var1[i]]][p_index]
  a2 = df[[all_comb$Var2[i]]][p_index]
  a3 = df[[all_comb$Var3[i]]][p_index]
  a4 = df[[all_comb$Var4[i]]][p_index]
  
  data.frame(i, rho = cor(df[p_index, target], (a1 - a2)/ (2 + a3 - a4) , use = 'pairwise.complete.obs' ))  } )
setDT(res)
res[order(abs(rho))]
res[!is.na(rho)]
all_comb[38415    ]

ggplot(df[p_index], aes((cont13 / cont14 ), target)) + geom_point() + geom_smooth()

```


## Percentile Transform

```{r p_transform}

p_vars = stri_join('p_', all_vars)
df[, (p_vars):=lapply(.SD, function(x) ecdf(x[train_index])(x) ), .SDcols = all_vars]

```
## RBF function

```{r rbf_functions}

rms <-function(y1, y2) sqrt( mean( (y1 - y2)^2 ))

rbf.create <- function(X, Y, nodes, kernel_params = 1.0, kernel_fun = function(d, c) exp(-c * d * d), dist_fun = 'L1' ){
  M = cbind(1, kernel_fun(dist(X, nodes, method = dist_fun), kernel_params) ) 
  w = ginv(t(M) %*% M) %*% t(M) %*% Y 
  
  return ( list(weights = w, nodes = nodes, kernel_params = kernel_params, kernel_fun = kernel_fun, dist_fun = dist_fun) )
}

rbf.predict <- function(model, X){
  
  nodes          = model$nodes
  weights        = model$weights
  dist_fun       = model$dist_fun
  kernel_params  = model$kernel_params
  kernel_fun     = model$kernel_fun
  
  M = kernel_fun(dist(X, nodes, method = dist_fun), kernel_params)
  pred = weights[1] + M %*% weights[-1]
  return ( as.numeric(pred) )
}

rbf_boot.create <- function(X, Y, max_nodes, n_runs = 10, kernel_params = 1.0, kernel_fun = function(d, c) exp(-c * d * d), dist_fun = 'L1' ){
  model_list = llply(seq(n_runs), function(run_id) {
    rbf.create(X, Y, as.matrix(X[sample.int(nrow(X), max_nodes),]), kernel_params = kernel_params, kernel_fun = kernel_fun,dist_fun = dist_fun )
  })
}

rbf_boot.predict <-function(models, X) {
  
  res = ldply(seq(length(models)), function(run_id) {
    y_pred = as.numeric(rbf.predict(models[[run_id]], X))
    data.frame(run_id, y_pred, id = seq(length(y_pred)) )
    })
    return (res)
}

rbf_boost.create <- function(X, Y, max_nodes, boot_runs = 10, kernel_params = 1.0, kernel_fun = function(d, c) exp(-c * d * d), dist_fun = 'L1' ){
  
  max_it = 10
  n_nodes = 2 * ncol(X)
  growth_rate = 1.5
  current_objective = Y
  
  all_models = list()
  
  for(it in 1:max_it)
  {
    
    start_time <- Sys.time()
    
    model_list = rbf_boot.create(X, current_objective, n_nodes, n_runs = boot_runs, kernel_params = kernel_params, kernel_fun = kernel_fun, dist_fun = dist_fun)
    res = rbf_boot.predict(model_list, X)
    
    setDT(res)
    res_agg = res[, .(y_pred = mean(y_pred)), by =.(id)]
    setorder(res_agg, id)
    
    elapsed = as.numeric(difftime(Sys.time(),start_time,units="secs"))/60
    
    print(sprintf('it: %d, nodes: %d, error: %f, elapsed: %f', it, n_nodes, rms(current_objective, res_agg$y_pred), elapsed ))
    
    current_objective = current_objective - res_agg$y_pred

    all_models[[it]] = model_list    
    
    n_nodes = pmax( round(growth_rate * n_nodes), n_nodes + 1)
    
    if(n_nodes > max_nodes)
      break
  }
  return (all_models)
}

rbf_boost.predict <- function(models, X, combine_boots = TRUE){
  
  res = NULL
  
  if(combine_boots){
     res = ldply(seq(length(models)), function(model_id1) {
       
       boot_models = models[[model_id1]]
       
       temp = ldply(seq(length(boot_models)), function(model_id2) {
         y_pred = as.numeric(rbf.predict(boot_models[[model_id2]], X))
         data.frame(model_id1, model_id2, y_pred, id = seq(length(y_pred)) )
      })
       
       setDT(temp)
       
       return (temp[, .(.N, y_pred = mean(y_pred, na.rm = TRUE), y_pred_sigma = sd(y_pred, na.rm = TRUE)), by =.(id, model_id1)])
     })
     
     setDT(res)
     res = res[order(model_id1), y_pred_cum := cumsum(y_pred), by =.(id)]
    
  }else{
     res = ldply(seq(length(models)), function(model_id1) {
       
       boot_models = models[[model_id1]]
       
       ldply(seq(length(boot_models)), function(model_id2) {
         y_pred = as.numeric(rbf.predict(boot_models[[model_id2]], X))
         data.frame(model_id1, model_id2, y_pred, id = seq(length(y_pred)) )
      })
     })
  }
   return (res)
}

create_cv_index <- function(n, nfolds){
  index = c(rep(seq(nfolds), n %/% nfolds), sample(seq(nfolds), n%%nfolds))
  return( sample(index, n) )
}


rbf_boost.create_cv <- function(X, Y, max_nodes, boot_runs = 10, nfolds =10,  kernel_params = 1.0, kernel_fun = function(d, c) exp(-c * d * d), dist_fun = 'L1' ){
  
  max_it = 10
  n_nodes = 2 * ncol(X)
  growth_rate = 1.5
  
  objective_list = llply(seq(nfolds), function(i) Y)
  
  cv_index = create_cv_index(nrow(X), nfolds)
  
  res_cv = matrix(0, max_it, nfolds)
  
  for(it in 1:max_it)
  {
    cv_errors = rep(0, nfolds)
    for (cv_fold in 1:nfolds){
      
       start_time <- Sys.time()
      
      current_objective = objective_list[[cv_fold]]
      
      model_list = rbf_boot.create(X[cv_index != cv_fold], current_objective[cv_index != cv_fold], n_nodes, n_runs = boot_runs, kernel_params = kernel_params, kernel_fun = kernel_fun, dist_fun = dist_fun)
      res  = rbf_boot.predict(model_list, X)
      
      setDT(res)
      res_agg = res[, .(y_pred = mean(y_pred)), by =.(id)]
      setorder(res_agg, id)
      
      error_in  = rms(current_objective[cv_index != cv_fold], res_agg$y_pred[cv_index != cv_fold])
      error_out = rms(current_objective[cv_index == cv_fold], res_agg$y_pred[cv_index == cv_fold])
      
      
      elapsed = as.numeric(difftime(Sys.time(),start_time,units="secs"))/60
      
      print(sprintf('it: %d, nodes: %d, cv: %d, error (in): %f, error (out): %f, elapsed: %f', it, n_nodes, cv_fold, error_in, error_out, elapsed) )
      
      objective_list[[cv_fold]] = current_objective - res_agg$y_pred
      cv_errors[cv_fold] = error_out
    }
    
    print(sprintf('it: %d, nodes: %d, cv-error: %f, sigma: %f', it, n_nodes, mean(cv_errors), sd(cv_errors)) )
    
    res_cv[it,] = cv_errors
    
    n_nodes = pmax( round(growth_rate * n_nodes), n_nodes + 1)
    
    if(n_nodes > max_nodes | n_nodes > nrow(X) * (nfolds - 1) / nfolds)
      break
  }
  return (res_cv)
}

```

## RBF

```{r rbf}
gauss_kernel = function(x, c) { exp(- (x/c) * (x/c)) }
linear_kernel = function(x, c) { x }

p_vars = stri_join('p_', all_vars)

max_nodes = 5000

dfs = df[train_index, ]

rbf_res = ldply(seq(10), function(run_id) {
  X = dfs[,p_vars, with = FALSE]
  model.rbf = rbf.create(X, dfs$target, as.matrix(X[sample.int(nrow(X), max_nodes),]),  kernel_params = 0.5, kernel_fun = linear_kernel)
  y_pred = as.numeric(rbf.predict(model.rbf,X))
  
  data.frame(run_id, y_pred, id = dfs$id)
})
setDT(rbf_res)

rbf_res[df, target := i.target, on=.(id) ]

rbf_res[, rmsqr(target, y_pred), by =.(run_id)]

rbf_res_sum = rbf_res[, .(y_pred = mean(y_pred), sigma = sd(y_pred) ), by =.(id)]
rbf_res_sum[df, target := i.target, on=.(id) ]

plot_profiles(rbf_res_sum$y_pred, dfs)

rmsqr(rbf_res_sum$target, rbf_res_sum$y_pred)


```

## RBF CV

```{r rbf_cv}
gauss_kernel = function(x, c) { exp(- (x/c) * (x/c)) }
linear_kernel = function(x, c) { x }

p_vars = stri_join('p_', all_vars)

max_nodes = 1024

my_index = sample( which(train_index), 1.0*sum(train_index))

models_boost =  rbf_boost.create(df[my_index,all_vars, with = FALSE],  df$target[my_index], max_nodes, boot_runs = 100, kernel_params = 1.0, kernel_fun = linear_kernel, dist_fun = 'L1' )
res = rbf_boost.predict(models_boost, df[my_index,all_vars, with = FALSE], combine_boots = TRUE)
setDT(res)

ggplot(res[order(id), .(error = rms(y_pred_cum, df$target[my_index])), by =.(model_id1) ] , aes(model_id1, error)) + geom_line() +  geom_point()

#boost results for each step, run with combine_boots = FALSE
res_conv = res[, .(y_pred = mean(y_pred)), by =.(id, model_id1 )]
res_conv[order(model_id1), y_pred_cum := cumsum(y_pred), by =.(id)]
ggplot(res_conv[order(id), .(error = rms(y_pred_cum, df$target[my_index])), by =.(model_id1) ] , aes(model_id1, error)) + geom_line() +  geom_point()


# CV ---------
#linear - 0.7147895 
cv_res = rbf_boost.create_cv(df[my_index, p_vars, with = FALSE],  df$target[my_index], max_nodes = 1024, boot_runs = 100, nfolds = 10, kernel_params = 1.0, kernel_fun = linear_kernel, dist_fun = 'L1' )
df_cv_res = data.table(it = seq(nrow(cv_res)), avg = apply(cv_res, 1, mean ), sigma = apply(cv_res, 1, sd ), cv_res )
ggplot(df_cv_res[avg>0], aes(it, avg)) + geom_line() + geom_ribbon(aes(it, ymin = avg - sigma, ymax = avg + sigma), alpha = 0.2, fill = 'blue')

#0.69834

```


#Submit
MY BEST: 0.84357
v1: 0.84357 min(0.8431303)
```{r submit, echo=FALSE}
  #model_pred = pred.xgb
  #df[pred.lgb_cv, target_lgb :=  i.avg, on=.(id)]
  #fwrite(df, file.path(working_folder,'Playground/Feb2021/data/df.csv'))
 
  file = file.path(working_folder, "Playground/Jan2021/submit_v1.rbf.csv")
  fwrite(df[test_index, .(id, target=target_lgb)], file = file, row.names = FALSE)
  zip(paste(file, '.zip', sep = ''), file, flags = '-r9Xj')
  print(file)

```


