---
title: "March Playground"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(stringi)
library(ggplot2)
library(gridExtra)
library(plyr)
library(forcats)
library(proxy)
library(MASS)

working_folder = 'D:/Github/KaggleSandbox'
#working_folder = file.path(Sys.getenv("HOME"), 'source/github/KaggleSandbox/')

source(file.path(working_folder, 'Utils/common.R'))
source(file.path(working_folder, 'Utils/rbf_utils.R'))

rms <-function(actual, model) {
  sqrt( mean( (actual - model) * (actual - model) ) )
}

```

## Load Data
```{r load_data}
load_existing = FALSE

if (load_existing) {
  df <- fread(file.path(working_folder,'Playground/Aug2021/data/df.csv'), check.names = TRUE)
} else{
  train <- fread(file.path(working_folder,'Playground/Aug2021/data/train.csv'), check.names = TRUE)
  test  <- fread(file.path(working_folder,'Playground/Aug2021/data/test.csv'),  check.names = TRUE) # 1459   80
  test[, loss :=NA]
  df = rbind(train, test)
  
  fwrite(df, file.path(working_folder,'Playground/Aug2021/data/df.csv'))
  
  gc(reset=TRUE)
}
setkey(df, id)
  
test_index = is.na(df$loss)
train_index = !test_index

obj_var = 'loss'
all_vars = names(df) %!in_set% c('id', obj_var)
cat_vars = names(which(sapply(df[,all_vars, with = FALSE], function(x) is.factor(x) | is.character(x) )))
con_vars = names(which(sapply(df[,all_vars, with = FALSE], function(x) is.numeric(x)  )))

df[, is_test:= is.na(loss)]

#pre-preprocess
#df[, cat10_1_ex  :=  fct_infreq(fct_lump_prop(stri_sub(cat10,1,1), 0.005, other_level = "OT")) ]
#df[, cat10_2_ex  :=  fct_infreq(fct_lump_prop(stri_sub(cat10,2,2), 0.005, other_level = "OT")) ]

convert_to_prob <-function(x, train_index){
  ecdf(x[train_index])(x)
}

convert_to_normal_prob <-function(x, train_index){
  max_sigma = pnorm(-5) #2.866516e-07
  qnorm(pmin(1-max_sigma,pmax(max_sigma, ecdf(x[train_index])(x))) )
}
#percentile transform - not useful
p_vars = stri_join('p_', all_vars)
df[, (p_vars):=lapply(.SD, function(x) ecdf(x[train_index])(x) ), .SDcols = all_vars]

n_vars = stri_join('n_', all_vars)
df[, (n_vars):=lapply(.SD, function(x) convert_to_normal_prob(x, train_index)), .SDcols = all_vars]

#w_vars = stri_join('w_', all_vars)
#df[, (w_vars):=lapply(.SD, function(x) winsoraze(x, x[train_index], 0.001) ), .SDcols = all_vars]

```


## GAM

```{r gam, echo=FALSE, eval = FALSE}
library(gam)

t_index_v = which(train_index)
t_index_v1 = sample(t_index_v, 0.1*length(t_index_v))

#s or lo
gam.formula= formula(stri_join('loss ~', stri_join(sprintf('s(%s, df=7)',n_vars), collapse = '+') ))
model.gam = gam(gam.formula, data=df[t_index_v1,c('loss',n_vars), with = FALSE], family=gaussian)

summary(model.gam)

df[, loss_pred_gam:=predict(model.gam, df) ]

plots = llply(n_vars, function(var_name) { #lgb_vars
    p = plot_profile(df$loss_pred_gam[train_index],  df$loss[train_index], df[[var_name]][train_index], bucket_count = 10, error_band = 'normal') +
      ggtitle(var_name) +  theme(title =element_text(size=8))
    return( ggplotGrob(p) )
  })
  marrangeGrob(plots, nrow = 5, ncol = 5, top = NULL)
#  ggsave(filename = file.path(working_folder,"Playground/Aug2021/profiles_gam.pdf"), plot = marrangeGrob(plots, nrow=5, ncol=5), device = 'pdf', width = 14, height = 8.5, dpi = 360)

rms(df$loss[train_index], df$loss_pred_gam[train_index])
```

## Caret

```{r caret, echo=FALSE, eval = FALSE}
library(caret)
#library(doParallel)
#detach("package:doParallel", unload = TRUE)

t_index_v = which(train_index)
t_index_v1 = sample(t_index_v, 1.0*length(t_index_v))

formula.caret    = formula(stri_join( "loss", ' ~ ', stri_join(n_vars, collapse = ' + ')))

set.seed(1234)
control = trainControl(method = "repeatedcv", number = 10, repeats = 3)

#KNN
#gamboost (mstop, prune), 
#gamLoess (span, degree), 
#gam(	select, method), 
#gamSpline (df)

#cl <- makePSOCKcluster(2)
#registerDoParallel(cl)

a = system.time(
model.gam <- train(formula.caret, data = df[t_index_v1, all.vars(formula.caret), with = FALSE], 
                   method = "gamSpline",
                   trControl = control,
                   tuneGrid = data.frame(df = c(3, 4, 5))
                   ))
print(a)
#stopCluster(cl)

plot(model.gam)

pred.gam = predict(model.gam, df, type = 'raw')

df[, loss_pred_gam := predict(model.gam, df) ]

```


## Plots

```{r plots, echo=FALSE}
s_index = sample.int(nrow(df), nrow(df))
plots = llply(all_vars %!in_set% c('id'), function(var_name){
  ggplot(df[s_index ], aes_string(var_name, group = 'is.na(loss)', color = 'is.na(loss)')) + geom_density(adjust = 0.1) + ggtitle(var_name)
  })
marrangeGrob(plots, nrow = 3, ncol = 3, top = NULL)


ggplot(df[train_index,], aes(loss)) + geom_bar()

ggplot(df[train_index,], aes(f81, group = loss, color = loss)) + geom_density()

plot_cormat(df[train_index, all_vars, with = FALSE ])
```


##Submit 
      
v1  - 7.93674 baseline (no optimization, no pre-processing)

```{r submit, echo=FALSE}
  #fwrite(df, file.path(working_folder,'Playground/Apr2021/data/df.csv'))
 
  file = file.path(working_folder, "Playground/Aug2021/submit_v1.gam.csv")
  #fwrite(df[test_index, .(id, target=target_lgb)], file = file, row.names = FALSE)
  fwrite(df[test_index, .(id, loss = loss_pred_gam)], file = file, row.names = FALSE)
  zip(paste(file, '.zip', sep = ''), file, flags = '-r9Xj')
  print(file)

```

#KNN
```{r knn_regression, eval = FALSE}
library(caret)

formula.knn    = formula(stri_join( 'loss', ' ~ ', stri_join(unique(c('f81')), collapse = ' + ')))

#control = trainControl(method = "repeatedcv", number = 10,repeats = 3)
control = trainControl("cv", number = 10)

t_index_v = which(train_index)
t_index_v1 = sample(t_index_v, 1*length(t_index_v))

dfs = df[t_index_v1, all.vars(formula.knn), with = FALSE]
system.time(model.knn <- train(formula.knn, data = dfs, 
                               method = "knn", #kknn
                               trControl = control,
                               tuneGrid = data.frame(k = seq(400, 450,50)), #use instead of tuneLength
                               metric = "RMSE"))
model.knn
plot(model.knn)

pred.knn = predict(model.knn, df, type = 'raw')

plot_profile(pred.knn[train_index],  df$loss[train_index], df[['f81']][train_index], bucket_count = 100, error_band = 'normal')

```



