---
title: "GBM Model for Zillow prices"
output: html_document
---
---
title: "Overfitting"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(reshape2)
library(tidyr)
library(ggplot2)
library(Hmisc)
library(plyr)
library(dplyr)
library(gridExtra)
library(corrplot)

library(gbm)
#library(np)
library(earth) 
library(rpart)
library(party)
library(caret)
library(randomForest)
library(nnet)
library(e1071)
library(MASS)
library(lubridate)

library(knitr)
library(foreach)

knitr::opts_chunk$set(echo = TRUE)
```

## Load data
```{r load_data}
rm(list = ls())

# READ DATA ---- 
max_it_mult = 1000

inf_lowlimit = 0.5

#dont set seed
#random_seed = 12345678
#set.seed(random_seed)

#working_folder = 'C:/Dev/Kaggle/'
working_folder = file.path(Sys.getenv("HOME"), 'source/github/KaggleSandbox/')

source(file.path(working_folder, 'Utils/common.R'))

property_info_file = file.path(working_folder,'Zillow/properties_2016.rds')

if(file.exists(property_info_file)){
  property_info = readRDS(property_info_file)
 
}else {
  property_info = read.csv(file.path(working_folder,'Zillow/properties_2016.csv') )
  
  convert_to_factors = c('airconditioningtypeid', 'architecturalstyletypeid', 
                         'buildingclasstypeid', 'buildingqualitytypeid', 'decktypeid', 
                         'fips', #area code
                         'heatingorsystemtypeid','propertylandusetypeid','storytypeid','typeconstructiontypeid',
                         'regionidcity', 'regionidcounty', 'regionidneighborhood','regionidzip', 'censustractandblock'
                         )
  
  for (name in convert_to_factors){
    property_info[,name] = factor(property_info[,name])
  }
  
  temp = property_info$taxdelinquencyyear 
  property_info$taxdelinquencyyear[temp >  50 & !is.na(temp)]  = 1900 + temp[temp >   50 & !is.na(temp)]
  property_info$taxdelinquencyyear[temp <= 50 & !is.na(temp)]  = 2000 + temp[temp <=  50 & !is.na(temp)]

  
  saveRDS(property_info, property_info_file)
}

#create a test data set
pred_dates = c(201610,201611,201612,201710,201711,201712)
pred_dates_ex = as.Date(as.character(100*pred_dates + 1), '%Y%m%d')
test = expand.grid(parcelid = property_info$parcelid, transactiondate = pred_dates_ex)

train <- read.csv(file.path(working_folder,'Zillow/train_2016_v2.csv'), colClasses = c('integer', 'numeric', 'Date'))

fun_var = 'logerror'
remove_vars = c('latitude', 'longitude', 'regionidcity', 'regionidneighborhood','regionidzip', 'censustractandblock',
             'propertycountylandusecode', 'propertyzoningdesc', 'rawcensustractandblock', 
             'assessmentyear', 'decktypeid', 'storytypeid',
             'structuretaxvaluedollarcnt', 'taxamount', 'taxvaluedollarcnt', 'lotsizesquarefeet', 'landtaxvaluedollarcnt',
             'poolcnt', 'pooltypeid10', 'pooltypeid2', 'pooltypeid7', 'buildingclasstypeid', 'typeconstructiontypeid')

non_vars = c('parcelid', 'transactiondate', 'latitude', 'longitude', 'regionidcity', 'regionidneighborhood','regionidzip', 'censustractandblock',
             'propertycountylandusecode', 'propertyzoningdesc', 'rawcensustractandblock', 
             't_year', 'taxdelinquencyyear', 'assessmentyear', 'yearbuilt', 'decktypeid', 'storytypeid',
             'structuretaxvaluedollarcnt', 'taxamount', 'taxvaluedollarcnt', 'lotsizesquarefeet', 'landtaxvaluedollarcnt',
             'poolcnt', 'pooltypeid10', 'pooltypeid2', 'pooltypeid7', 'buildingclasstypeid', 'typeconstructiontypeid') #exclude sale_year and month

nonsig_vars = c('fireplaceflag', 'yardbuildingsqft26', 'regionidcounty', 'poolsizesum', 'finishedsquarefeet13', 'basementsqft', 
                'architecturalstyletypeid', 'taxdelinquencyflag', 'yardbuildingsqft17')

#all data transforms
pinfo = property_info

pinfo$structuretaxvaluedollarcnt_pct = pinfo$structuretaxvaluedollarcnt/pinfo$taxvaluedollarcnt
pinfo$taxamount_pct = pinfo$taxamount/pinfo$taxvaluedollarcnt
pinfo$taxvaluedollarcnt_log = log(pinfo$taxvaluedollarcnt)
pinfo$lotsizesquarefeet_log = log(pinfo$lotsizesquarefeet)
pinfo$landtaxvaluedollarcnt_pct = pinfo$landtaxvaluedollarcnt/pinfo$taxvaluedollarcnt
pinfo$taxamount_pct[pinfo$taxamount_pct > 1 & !is.na(pinfo$taxamount_pct)] = NA

levels(pinfo$taxdelinquencyflag) <- c('N', 'Y')
levels(pinfo$fireplaceflag) <-c('false', 'true')
levels(pinfo$hashottuborspa) <-c('false', 'true')

pinfo = pinfo[, c('parcelid', names(pinfo) %!in_set% remove_vars)]

df       =  merge(train, pinfo, by = 'parcelid', all.x = TRUE)
df_test  =  merge(test,  pinfo, by = 'parcelid', all.x = TRUE)

df      = mutate(df,      t_year = year(transactiondate), t_month =  month(transactiondate), age = t_year - yearbuilt, taxdelinquency_age =  t_year - taxdelinquencyyear)
df_test = mutate(df_test, t_year = year(transactiondate), t_month =  month(transactiondate), age = t_year - yearbuilt, taxdelinquency_age =  t_year - taxdelinquencyyear)


# summary
str(df[, names(df) %!in_set% non_vars])
summary(df[, names(df) %!in_set% non_vars])

con_vars = (names(df) %!in_set% non_vars) %in_set% names(which(sapply(df, is.numeric)))
cat_vars = (names(df) %!in_set% non_vars) %in_set% names(which(sapply(df, is.factor))) 

ldply(con_vars, function(colname) {
  x = df[,colname]
  data.frame(colname, na_count = sum(is.na(x)), na_pct = sum(is.na(x))/length(x), std = sd(x, na.rm = T) ) } )

ldply(cat_vars, function(colname) {
  x = df[,colname]
  data.frame(colname, count = length(levels(x)), levels = paste(levels(x), collapse = '|') ) } )

summary(df[, cat_vars %!in_set% non_vars])


ggplot(df, aes(logerror)) + stat_ecdf()
ggplot(df, aes(taxamount_pct, logerror)) + geom_point(size = 0.1 ) + geom_smooth()
ggplot(df, aes(buildingclasstypeid, logerror)) + stat_boxplot()
ggplot(df, aes(basementsqft, logerror )) + geom_point(size = 0.1 ) + geom_smooth()

gc()
```


## GBM All
cv(5) = 0.0257
```{r gbm_all_model, fig.width = 8, fig.height = 6, dpi = 150, eval = TRUE, echo=FALSE}
start_time <- proc.time()

allvars =  unique(names(df) %!in_set% c(non_vars, nonsig_vars, fun_var))

formula.all = formula (paste( fun_var, ' ~', paste(allvars, collapse = '+')) )

corr_matrix = cor(df[,all.vars(formula.all) %in_set% names(which(sapply(df, is.numeric))) ], use="pairwise.complete.obs")
corrplot(corr_matrix, method="number", number.cex = 0.5, number.digits = 1)
#corrplot(corr_matrix, method="circle", number.cex = 0.5, order="hclust")

print(formula.all)
print(length(allvars))

var.monotone = rep(0, length(allvars)) #1-increasing, -1 - decreasing, 0: any
var.monotone[allvars %in% c('taxdelinquency_age')] =   1
var.monotone[allvars %in% c('taxamount_pct')] =  -1

max_it = 20*max_it_mult #64k is for s=0.001, 

model.gbm_all = gbm(formula.all, 
                data = df[, all.vars(formula.all)], 
                distribution = 'gaussian',
                n.trees = max_it,
                shrinkage = 0.001, #0.001
                bag.fraction = 0.8,
                cv.folds = 5, #5
                interaction.depth = 3,#3
                train.fraction = 1.0,
                var.monotone = var.monotone,
                n.cores = 4,
                verbose = FALSE)

#show best iteration
best_it_all = gbm.perf(model.gbm_all, method = 'cv') 
print(best_it_all)
grid()
pred.gbm_all = predict(model.gbm_all, n.trees = best_it_all, newdata = df)

plot_gbmiterations(model.gbm_all)

#show importance
vars.importance_all = summary(model.gbm_all, n.trees = best_it_all, plotit=FALSE) # influence
plot_gbminfluence(vars.importance_all[vars.importance_all$rel.inf>=inf_lowlimit,])
kable(vars.importance_all[vars.importance_all$rel.inf>=inf_lowlimit,])
kable(vars.importance_all[vars.importance_all$rel.inf< inf_lowlimit,])

imp_vars = as.character(vars.importance_all$var)[vars.importance_all$rel.inf>=inf_lowlimit]

write.csv(vars.importance_all, file.path(working_folder,'Zillow/var.importance.all.csv'))

#plot interactions
level2_interactions = gbm_interactions(model.gbm_all,  df[, all.vars(formula.all)], iter = best_it_all, 1, 2)
level2_interactions = filter(level2_interactions, interaction_score>0.05)
plot_gbminteractions(level2_interactions)
kable(level2_interactions)

plots = plot_gbmpartial(model.gbm_all, best_it_all, imp_vars, output_type = 'link')
marrangeGrob(plots, nrow=3, ncol=3)

plots = plot_gbmpartial_2d(model.gbm_all, best_it_all, as.character(filter(level2_interactions, interaction_score>0.1)$vars), output_type = 'link')
marrangeGrob(plots, nrow=2, ncol=2)


plots <- llply(names(df) %in_set% imp_vars, function(vname){
  plot_result = plot_profile(pred.gbm_all, df[,fun_var], df[, vname], bucket_count = 10, min_obs = 10, error_band ='normal') + ggtitle(vname)
  return (plot_result)
})
marrangeGrob(plots, nrow=3, ncol=3)


print((proc.time() - start_time)[3])

```


## GBM CV

```{r gbm_cv, fig.width = 8, fig.height = 6, dpi = 150, eval = FALSE, echo=TRUE}
start_time <- proc.time()

cv_folds = 0

allvars =  unique(c(sig_vars, 'cluster_group') %!in_set% c(non_vars, 'sub_area'))
#allvars =  unique(c(sig_vars) %!in_set% c(non_vars, 'sub_area'))

formula.all = formula (paste( 'price_log ~', paste(allvars, collapse = '+')) )

corr_matrix = cor(df[,all.vars(formula.all) %in_set% names(which(sapply(df, is.numeric))) ], use="complete.obs")
corrplot(corr_matrix, method="number", number.cex = 0.5, number.digits = 1)
corrplot(corr_matrix, method="circle", number.cex = 0.5, order="hclust")

print(formula.all)
print(length(allvars))

var.monotone = rep(0, length(allvars)) #1-increasing, -1 - decreasing, 0: any
var.monotone[allvars %in% c('full_sq','cafe_count_5000', 'usdrub', 'state', 'num_room')] = 1
var.monotone[allvars %in% c('metro_min_walk','metro_min_avto', 'fitness_km')] = -1
#var.monotone[allvars %in% c('full_sq','full_sq_log', 'num_room','state', 'usdrub','eurrub', 'kitch_sq', 'mosque_km', 'life_sq', 'cafe_count_5000', 'ppi')] =  1
#var.monotone[allvars %in% c('metro_min_walk', 'metro_min_avto', 'fitness_km', 'sadovoe_km', 'public_healthcare_km', 'green_zone_km', 'kindergarten_km', 'workplaces_km', 'hospice_morgue_km', 'additional_education_km', 'office_sqm_1500_log')] =  -1

max_it = 60*max_it_mult #60k is for s=0.001, 

model.gbm_cv = gbm(formula.all, 
                data = df[train_index, all.vars(formula.all)], 
                distribution = 'gaussian',
                n.trees = max_it,
                shrinkage = 0.001, #0.001
                bag.fraction = 0.8,
                interaction.depth = 2,#3
                cv.folds = cv_folds, #5
                train.fraction = 1.0,
                var.monotone = var.monotone,
                n.cores = 4,
                verbose = FALSE)

if(cv_folds == 0){
  #show best iteration
  best_it_cv = max_it
}else{
  best_it_cv = gbm.perf(model.gbm_cv, method = 'cv') 
  print(best_it_cv)
  grid()
}

plot_gbmiterations(model.gbm_cv)

pred.gbm_cv = exp(predict(model.gbm_cv, n.trees = best_it_cv, newdata = df)) - 1.0

#plot interactions
level2_interactions = gbm_interactions(model.gbm_cv,  df[train_index, all.vars(formula.all)], iter = best_it_cv, 1, 2)
plot_gbminteractions(level2_interactions[level2_interactions$interaction_score>0.05,])
kable(level2_interactions[level2_interactions$interaction_score>0.05,])

#show importance
vars.importance_cv = summary(model.gbm_cv, n.trees = best_it_cv, plotit=FALSE) # influence
plot_gbminfluence(vars.importance_cv[vars.importance_cv$rel.inf>inf_lowlimit,])
kable(vars.importance_cv[vars.importance_cv$rel.inf>=inf_lowlimit,])
kable(vars.importance_cv[vars.importance_cv$rel.inf<inf_lowlimit,])

write.csv(vars.importance_cv, file.path(working_folder,'SberbankHousing/var.importance.csv'))

imp_vars = as.character(vars.importance_cv$var)[vars.importance_cv$rel.inf>=.1]

#partial dependence
plots = plot_gbmpartial(model.gbm_cv, best_it_cv, imp_vars, output_type = 'link')
marrangeGrob(plots, nrow=3, ncol=3)

plots = plot_gbmpartial_2d(model.gbm_cv, best_it_cv, as.character(level2_interactions$vars[level2_interactions$interaction_score>0.1]), output_type = 'link')
marrangeGrob(plots, nrow=2, ncol=2)

#profiles (norm) with respect to model vars
for(vname in c('sub_area', 'full_sq', 'sale_time') ){
  print(plot_profile(log(pred.gbm_cv[train_index]+1), log(df$price_doc[train_index]+1), df[train_index, vname], bucket_count = 20, min_obs = 10, error_band ='normal') + ggtitle(vname))
}
plots <- llply(imp_vars %in_set% names(df), function(vname){
  plot_result = plot_profile(log(pred.gbm_cv[train_index]+1), log(df$price_doc[train_index]+1), df[train_index, vname], bucket_count = 10, min_obs = 10, error_band ='normal') + ggtitle(vname)
  return (plot_result)
})
marrangeGrob(plots, nrow=3, ncol=3)

names(which(sapply(df, is.factor)))
      
#profiles with respect to categorical variables
residual_vars = names(which(sapply(df, is.factor))) %!in_set% c(non_vars, all.vars(formula.all))
plots <- llply(residual_vars %in_set% names(df), function(vname){
  plot_result = plot_profile(log(pred.gbm_cv[train_index]+1), log(df$price_doc[train_index]+1), df[train_index, vname], bucket_count = 10, min_obs = 10, error_band ='normal') + ggtitle(vname)
  return (plot_result)
})
marrangeGrob(plots, nrow=3, ncol=3)

residual_con_vars = names(which(sapply(df, is.numeric))) %!in_set% c(non_vars, all.vars(formula.all))
residual = df$price_log - log(pred.gbm_cv + 1)

var_cor = ldply(residual_con_vars, function(vname) data.frame(name = vname, cor = cor(residual[train_index], df[train_index,vname], use="complete.obs")))
var_cor = head(var_cor[order(abs(var_cor$cor), decreasing = TRUE),], 4*9)
#profiles with respect to con variables
plots <- llply(as.character(var_cor$name) %in_set% names(df), function(vname){
  plot_result = plot_profile(log(pred.gbm_cv[train_index]+1), log(df$price_doc[train_index]+1), df[train_index, vname], bucket_count = 10, min_obs = 10, error_band ='normal') + ggtitle(vname)
  return (plot_result)
})
marrangeGrob(plots, nrow=3, ncol=3)


print((proc.time() - start_time)[3]/3600)
```


## Summary
```{r res_print, fig.width = 8, fig.height = 6, dpi = 150, eval = FALSE, echo=TRUE}

# Solution  ---- 
predictions = predict(model.gbm_all, n.trees = best_it_all, newdata = df_test)

predictions[is.na(predictions)] = 0

df_out = mutate(select(df_test, parcelid, transactiondate), value = round(predictions,4) )
df_out = mutate(df_out, date = 100*year(transactiondate) + month(transactiondate) )
df_out <- spread(select(df_out,-transactiondate), date, value)


## print solution ---- 
submit <- rename(df_out, ParcelId = parcelid)
submit = submit[order(submit$ParcelId),]
file = file.path(working_folder, "Zillow/submittion.csv")
write.csv(submit[1:10,], file = file, row.names = FALSE, quote = FALSE)
zip(paste(file, '.zip', sep = ''), file, flags = "-9jX")
print(file)

```
