---
title: "Santander Transaction Model: MARS"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5, dpi = 240)
options(warn=-1)

library(plyr)

library(data.table)
library(stringi)
library(ggplot2)
library(tabplot)
library(gridExtra)
library(zip)
library(corrplot)
library(forcats)
library(e1071)
library(lubridate)
library(caret)

library(lightgbm)
library(gbm)
library(earth)
library(car)
library(umap)
library(MASS)

library(rBayesianOptimization)

#library(lightgbm)

#working_folder = 'C:/Dev/Kaggle/'
#working_folder = 'F:/Github/KaggleSandbox/'
working_folder = file.path(Sys.getenv("HOME"), 'source/github/KaggleSandbox/')

source(file.path(working_folder, '/Utils/common.R'))
```

## Load Data

```{r load_data}

  df_train = fread(file.path(working_folder,'santander_transaction/data/train.csv'), check.names=T)#, nrows = 10000)
  df_test  = fread(file.path(working_folder,'santander_transaction/data/test.csv'),  check.names=T)#, nrows = 10000)

  df_train[,is_train:=TRUE  ]
  df_test[, is_train:=FALSE ]
  df_test[, target:=NA ]
  
  df = rbind(df_train, df_test)
  df = df[sample.int(nrow(df), nrow(df)),]
  train_index = df$is_train
  
  df_test = NULL
  gc(reset = TRUE)
  
  #normalize data
  #var_names = names(df)[grep('var', names(df))]
  #df[, (var_names):=lapply(.SD, function(x) ecdf(x)(x)), .SDcols = var_names]

  #add noise
  var_names = names(df)[grep('var', names(df))]
  df[is_train==TRUE, (var_names):=lapply(.SD, function(x) x + 0.05*rnorm(length(x)) ), .SDcols = var_names]

```

## Plot data

```{r plot_data}

  var_inf = fread(file.path(working_folder,"santander_transaction/gbm.var_inf.d1.csv"))

  ggplot(df, aes(var_0, group = is_train)) + stat_ecdf()
  
  
  ggplot(df_train[1:10000,], aes(seq(target), target )) + geom_point(alpha = 0.2) + geom_jitter()+geom_smooth()
  
  ggplot(df, aes(var_81, var_139)) + geom_point(alpha = 0.2, size = 0.2) + facet_wrap(~is_train) + scale_color_manual(values = c('red', 'black'))
  
  plots = llply(var_inf$var[1:50], function(var_name){
    p = ggplot(df[train_index,][1:10000,], aes_string(seq(10000), var_name, color = 'target') ) + geom_point(size = 0.5) + scale_colour_gradient(low ='black', high = 'red') + theme(legend.position = 'none')
    return(ggplotGrob(p))
  })
  marrangeGrob(plots, nrow = 5, ncol = 10, top = NULL)
  
    #ggplot(df_train[1:30000,], aes(var_80, var_139)) + geom_point(alpha = 0.2) + geom_rug(alpha = 0.01) + facet_wrap(~target)
  ggplot(df[is_train==TRUE,], aes(var_80, var_139)) + geom_bin2d() + facet_wrap(~target) + scale_fill_custom('jet', discrete = FALSE)
  ggplot(df[is_train==TRUE,], aes(var_81, var_139, z = target)) + stat_summary_2d(fun = function(x) mean(x)) + scale_fill_custom('jet', discrete = FALSE)
  #ggplot(df_train, aes(var_81, var_139, z = target)) + stat_summary_hex(fun = function(x) mean(x)) +  scale_fill_custom('jet', discrete = FALSE)
  
  imp_vars = c('var_81','var_53','var_164','var_109','var_139','var_166','var_78','var_12','var_177','var_80','var_110','var_26','var_6')
  all_combinations = t(combn(imp_vars, 2))
  plots = llply(seq(nrow(all_combinations)), function(i){
    p = ggplot(df[is_train == TRUE,], aes_string(all_combinations[i,1], all_combinations[i,2])) + geom_bin2d() + facet_wrap(~target) + scale_fill_custom('jet', discrete = FALSE) + theme(legend.position = 'none')
    return(ggplotGrob(p))
  })
  marrangeGrob(plots, nrow = 5, ncol = 9, top = NULL)
  
  plots = llply(seq(nrow(all_combinations)), function(i){
    ggplot(df_train, aes_string(all_combinations[i,1], all_combinations[i,2], z = 'target')) + stat_summary_2d(fun = function(x) ifelse(length(x)<8, NA, mean(x))) + scale_fill_custom('jet', discrete = FALSE)+ theme(legend.position = 'none')
    #ggplot(df_train, aes_string(all_combinations[i,1], all_combinations[i,2], z = 'target')) + stat_summary_hex(fun = function(x) mean(x)) + scale_fill_custom('jet', discrete = FALSE)+ theme(legend.position = 'none')
  })
  marrangeGrob(plots, nrow = 5, ncol = 9, top = NULL)

  #plot model prediction
  df_train_wm = cbind(df[tindex,], mdl=pred.mars[tindex], actual=actual[tindex])
  plots = llply(seq(nrow(all_combinations)), function(i){
    ggplot(df_train_wm, aes_string(all_combinations[i,1], all_combinations[i,2], z = 'mdl')) + stat_summary_2d(bins =100, fun = function(x) mean(x)) + scale_fill_custom('jet', discrete = FALSE)+ theme(legend.position = 'none')
    #ggplot(df_train, aes_string(all_combinations[i,1], all_combinations[i,2], z = 'target')) + stat_summary_hex(fun = function(x) mean(x)) + scale_fill_custom('jet', discrete = FALSE)+ theme(legend.position = 'none')
  })
  marrangeGrob(plots, nrow = 5, ncol = 9, top = NULL)

   p1 = ggplot(df_train_wm, aes(var_81, var_139, z = mdl))    + stat_summary_2d(bins =100, fun = function(x) mean(x)) + scale_fill_custom('jet', discrete = FALSE)#+ theme(legend.position = 'none')
   p2 = ggplot(df_train_wm, aes(var_81, var_139, z = target)) + stat_summary_2d(bins =100, fun = function(x) ifelse(length(x)<4, NA, mean(x))) + scale_fill_custom('jet', discrete = FALSE)#+ theme(legend.position = 'none')
   grid.arrange(p1, p2, nrow = 1)
  
    #tableplot(df_train[1:10000,], select = c('target',stri_join('var_', seq(0, 10))), sortCol = 'var_0')
  #tableplot(df_train[1:10000,], select = c('target','var_1'), sortCol = 'var_0')
   
   num_vars  = names(which(sapply(df, is.numeric))) %!in_set% c('target')
   corr_matrix = cor(df[, ..num_vars ], use="complete.obs")
   corrplot(corr_matrix, method="number", number.cex = 0.5)
   corrplot(corr_matrix, method="circle", order="hclust")
   
   ggplot(data = melt(corr_matrix), aes(x=Var1, y=Var2, fill=value)) + geom_tile() + scale_fill_custom('jet', discrete = FALSE)
   ggplot(data = melt(corr_matrix-diag(rep(1,nrow(corr_matrix)))), aes(x=Var1, y=Var2, fill=value)) + geom_tile() + scale_fill_custom('jet', discrete = FALSE)
   

  # ----------- UMAP    -------------------
  m_data = df_train[,var_inf$var, with = FALSE]
 
  data_map = umap(m_data)
  
  ggplot(data.frame(data_map$layout, label = factor( df_train[['target']] )), aes(X1, X2, group = label, color = label)) + 
    geom_point(size = 0.1) + scale_color_manual(values = c('black', 'red'))

  #sammon #MASS
  sammon_map = sammon(dist(m_data[1:2000,]), tol = 1e-6)
  ggplot(data.frame(sammon_map$points, label = factor( df_train[['target']][1:2000] )), aes(X1, X2, group = label, color = label)) + 
    geom_point(size = 0.1) + scale_color_manual(values = c('black', 'red'))

```


## Logistic regression

```{r logreg_model}
tindex = df$is_train

obj_var = 'target'
actual = df[[obj_var]]

exclude_vars = c('ID_code', 'is_train', obj_var)
all_vars = names(df) %!in_set% c(exclude_vars)

formula.glm = formula(stri_join( obj_var, ' ~ ', stri_join(unique(all_vars), collapse = ' + ')))

model.glm = glm(formula.glm, df[tindex,], family = binomial(link = "logit"))
summary(model.glm)
vif(model.glm)

#could be dec: var_41, var_7, var_98        var_10       var_185
#could be inc:        var_38       var_117        var_60 

pred.glm          = predict(model.glm, newdata = df, type = 'response')
pred.glm.logodds  = predict(model.glm, newdata = df, type = 'link')
plot_binmodel_roc(actual[tindex], pred.glm[tindex])
plot_binmodel_cdf(actual[tindex], pred.glm[tindex])
plot_binmodel_percentiles(actual[tindex], pred.glm[tindex], 100)
gbm.roc.area(actual[tindex], pred.glm[tindex]) #0.861283

```


## Projection Pursuit Regression

```{r ppr_model}
tindex = df$is_train

obj_var = 'target'
actual = df[[obj_var]]

exclude_vars = c('ID_code', 'is_train', obj_var)
all_vars = names(df) %!in_set% c(exclude_vars)

formula.glm = formula(stri_join( obj_var, ' ~ ', stri_join(unique(all_vars), collapse = ' + ')))

model.ppr = ppr(formula.glm, df[tindex,], nterms = 3)
summary(model.ppr)

pred.ppr         = predict(model.ppr, newdata = df, type = 'response')

```


## LightGBM

```{r lgbm_model}
tindex = df$is_train

obj_var = 'target'
actual = df[[obj_var]]

exclude_vars = c('ID_code', 'is_train', obj_var) #replaced with logs

all_vars = names(df) %!in_set% c(exclude_vars)

set.seed(1234)

lgb.train = lgb.Dataset(data=data.matrix(df[is_train == TRUE , all_vars, with=F]), 
                        label=df[is_train == TRUE, ][[obj_var]], 
                        colnames = all_vars,
                        categorical_feature = NULL)

lgb.grid = list(objective = "binary",
                metric = "auc",
                min_sum_hessian_in_leaf = 10,
                feature_fraction = 1.0,
                bagging_fraction = 0.95,
                is_unbalance = FALSE)

lgb.auc = function(preds, dtrain){
  actual = getinfo(dtrain, "label")
  score  = gbm.roc.area(actual, preds)
  return(list(name = "auc", value = score, higher_better = TRUE))
}

#cross validation
lgb.model.cv = lgb.cv(params = lgb.grid, data = lgb.train, 
                      learning_rate = 0.01,
                      num_threads = 4, 
                      nrounds = 20000, 
                      early_stopping_rounds = 100, eval_freq = 100, eval = lgb.auc, 
                      nfold = 5, 
                      boost_from_average = TRUE)

best.iter = lgb.model.cv$best_iter #
lgb.model.cv$best_score
#best.iter = 603

model.lgb = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.01,
                      num_threads = 4, nrounds = best.iter,
                      eval_freq = 20, eval = lgb.auc,
                      boost_from_average = TRUE, verbose = 1)

var_imp   = lgb.importance(model.lgb, percentage = TRUE)
lgb.plot.importance(var_imp, top_n = 20, measure = "Gain")
#var_contr = lgb.interprete(lgb.model, lgb.train, 1:5)

pred.lgb = predict(model.lgb, data.matrix(df[,all_vars, with=F]) )

plot_binmodel_percentiles(actual[tindex], pred.lgb[tindex], 100)
plot_binmodel_roc(actual[tindex], pred.lgb[tindex])
```


## LightGBM: Param Tune

```{r lgbm_model}
lgb_cv_bayes <- function(learning_rate, min_sum_hessian_in_leaf, num_leaves) {
    set.seed(132140937) # to remove random noise from the parameters
  
    cv <- lgb.cv(params = list(objective = "binary",
                metric = "auc",
                learning_rate = learning_rate, #0.1
                min_sum_hessian_in_leaf = min_sum_hessian_in_leaf, #10
                num_leaves = num_leaves, #31
                bagging_fraction = 0.95,
                boost_from_average = TRUE,
                is_unbalance = FALSE), 
                data = lgb.train, 
                      num_threads = 4, 
                      nrounds = 20000, 
                      early_stopping_rounds = 50, eval_freq = 50, eval = lgb.auc, 
                      nfold = 5, 
                      boost_from_average = TRUE,
                verbose = -1)
  gc(reset = TRUE)
  
  list(Score = cv$best_score, Pred = cv$best_iter)
}

OPT_Res <- BayesianOptimization(lgb_cv_bayes,
                                bounds = list(
                                learning_rate = c(0.01, 0.1),
                                min_sum_hessian_in_leaf = c(0, 10),
                                num_leaves = c(1L, 256L)), #127
                                init_grid_dt = NULL, 
                                init_points = 10, #10
                                n_iter = 10,     #50
                                acq = "ucb", kappa = 2.576, eps = 0.0,
                                verbose = TRUE)
opt_res = data.table(OPT_Res$History, it_count=as.numeric(OPT_Res$Pred))
#setorder(opt_res, Value)

tableplot(opt_res, sortCol = 'Value')
tableplot(opt_res, sortCol = 'Round')

ggplot(opt_res, aes(eta, Value)) + geom_point(alpha = 0.6) + geom_smooth()
ggplot(opt_res, aes(subsample, Value, size = max_depth, color =min_child_weight)) + geom_point(alpha = 0.6) + geom_smooth()
ggplot(opt_res, aes(max_depth, Value, size = min_child_weight)) + geom_point(alpha = 0.3) + geom_smooth()


```

## Save Results
gbm - 0.897
xgb - 0.899
lgb - 0.895

```{r save_results}

submit = df[,.(ID_code, target = pred.lgb)]

submit = submit[df$is_train==FALSE,]

setorder(submit, ID_code)

file = file.path(working_folder, "santander_transaction/solution_lgb.csv")
  
fwrite(submit, file = file, row.names = FALSE)

zip(paste(file, '.zip', sep = ''), file)

system(paste('bzip2 -zk ',file, sep = ''))
  
print(file)

#fullVisitorId,PredictedLogRevenue

```