---
title: "GBM Model for Zillow prices"
output: html_document
---
---
title: "Overfitting"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(reshape2)
library(tidyr)
library(ggplot2)
library(Hmisc)
library(plyr)
library(dplyr)
library(gridExtra)
library(corrplot)

#library(gbm)
library(gbm3) # new version of gbm package
#library(np)
library(earth) 
library(rpart)
library(party)
library(caret)
library(randomForest)
library(nnet)
library(e1071)
library(lubridate)

library(knitr)
library(foreach)
library(car)

knitr::opts_chunk$set(echo = TRUE)
```

## Load data
```{r load_data}
rm(list = ls())

# READ DATA ---- 
max_it_mult = 1000

inf_lowlimit = 0.5

#dont set seed
#random_seed = 12345678
#set.seed(random_seed)

#working_folder = 'C:/Dev/Kaggle/'
working_folder = file.path(Sys.getenv("HOME"), 'source/github/KaggleSandbox/')

source(file.path(working_folder, 'Utils/common.R'))

property_info_file = file.path(working_folder,'Zillow/properties_2016.rds')

if(file.exists(property_info_file)){
  property_info = readRDS(property_info_file)
}else {
  property_info = read.csv(file.path(working_folder,'Zillow/properties_2016.csv') )
  
  convert_to_factors = c('airconditioningtypeid', 'architecturalstyletypeid', 
                         'buildingclasstypeid', 'buildingqualitytypeid', 'decktypeid', 
                         'fips', #area code
                         'heatingorsystemtypeid','propertylandusetypeid','storytypeid','typeconstructiontypeid',
                         'regionidcity', 'regionidcounty', 'regionidneighborhood','regionidzip', 'censustractandblock'
                         )
  
  for (name in convert_to_factors){
    property_info[,name] = factor(property_info[,name])
  }
  
  temp = property_info$taxdelinquencyyear 
  property_info$taxdelinquencyyear[temp >  50 & !is.na(temp)]  = 1900 + temp[temp >   50 & !is.na(temp)]
  property_info$taxdelinquencyyear[temp <= 50 & !is.na(temp)]  = 2000 + temp[temp <=  50 & !is.na(temp)]

  
  saveRDS(property_info, property_info_file)
}

#create a test data set
pred_dates = c(201610,201611,201612,201710,201711,201712)
pred_dates_ex = as.Date(as.character(100*pred_dates + 1), '%Y%m%d')
test = expand.grid(parcelid = property_info$parcelid, transactiondate = pred_dates_ex)

train <- read.csv(file.path(working_folder,'Zillow/train_2016_v2.csv'), colClasses = c('integer', 'numeric', 'Date'))

fun_var = 'logerror'
remove_vars = c('latitude', 'longitude', #should not be there
                'regionidcity', 'regionidneighborhood','regionidzip', 'censustractandblock',#too many levels
                'propertycountylandusecode', 'propertyzoningdesc', 'rawcensustractandblock',  #too many levels
                'assessmentyear',  #no variation
                'decktypeid', 'storytypeid', #no variation
                'structuretaxvaluedollarcnt', # use % of taxvaluedollarcnt
                'taxamount',  # use % of taxvaluedollarcnt
                'taxvaluedollarcnt', # use log
                'lotsizesquarefeet', # use log
                'calculatedfinishedsquarefeet', #use log
                'landtaxvaluedollarcnt',# total - structure
                'poolcnt', 'pooltypeid10', 'pooltypeid2', 'pooltypeid7', 
                'buildingclasstypeid', #mostly na (only 16 values)
                'typeconstructiontypeid')

non_vars = c(remove_vars, 'parcelid', 'transactiondate', 
             't_year', #no variation
             'taxdelinquencyyear', #replaced with age
             'yearbuilt' #replaced with age
             ) #exclude sale_year and month

nonsig_vars = c('fireplaceflag', 'yardbuildingsqft26', 'regionidcounty', 'poolsizesum', 
                'finishedsquarefeet12','finishedsquarefeet13', 'finishedsquarefeet6','finishedsquarefeet15', 'basementsqft', 
                'architecturalstyletypeid', 'taxdelinquencyflag', 'yardbuildingsqft17', 'bathroomcnt', 'fullbathcnt', 'finishedfloor1squarefeet', 'structuretaxvaluedollarcnt_pct',
                	'threequarterbathnbr', 	'finishedsquarefeet50_diff', 'fips') #almost no splits (inf < 0.1)

#all data transforms
pinfo = property_info

pinfo$structuretaxvaluedollarcnt_pct = pinfo$structuretaxvaluedollarcnt/pinfo$taxvaluedollarcnt
pinfo$taxamount_pct = pinfo$taxamount/pinfo$taxvaluedollarcnt
pinfo$taxvaluedollarcnt_log = log(pinfo$taxvaluedollarcnt)
pinfo$lotsizesquarefeet_log = log(pinfo$lotsizesquarefeet)
pinfo$calculatedfinishedsquarefeet_log = log(pinfo$calculatedfinishedsquarefeet)
pinfo$landtaxvaluedollarcnt_pct = pinfo$landtaxvaluedollarcnt/pinfo$taxvaluedollarcnt
pinfo$taxamount_pct[pinfo$taxamount_pct > 1 & !is.na(pinfo$taxamount_pct)] = NA

pinfo$finishedsquarefeet50_diff = pinfo$finishedsquarefeet50 - pinfo$finishedfloor1squarefeet

levels(pinfo$taxdelinquencyflag) <- c('N', 'Y')
levels(pinfo$fireplaceflag) <-c('false', 'true')
levels(pinfo$hashottuborspa) <-c('false', 'true')

pinfo = pinfo[, c(names(pinfo) %!in_set% remove_vars)]

df       =  merge(train, pinfo, by = 'parcelid', all.x = TRUE)
df_test  =  merge(test,  pinfo, by = 'parcelid', all.x = TRUE)

df      = mutate(df,      t_year = year(transactiondate), t_month =  month(transactiondate),t_day =  pmin(30, day(transactiondate)), age = t_year - yearbuilt, taxdelinquency_age =  t_year - taxdelinquencyyear)
df_test = mutate(df_test, t_year = year(transactiondate), t_month =  month(transactiondate),t_day =  pmin(30, day(transactiondate)), age = t_year - yearbuilt, taxdelinquency_age =  t_year - taxdelinquencyyear)

rm(list = c('pinfo', 'property_info'))
#rm(list = c('df_test'))

# summary
str(df[, names(df) %!in_set% non_vars])
summary(df[, names(df) %!in_set% non_vars])

con_vars = (names(df) %!in_set% non_vars) %in_set% names(which(sapply(df, is.numeric)))
cat_vars = (names(df) %!in_set% non_vars) %in_set% names(which(sapply(df, is.factor))) 

ldply(con_vars, function(colname) {
  x = df[,colname]
  data.frame(colname, na_count = sum(is.na(x)), na_pct = sum(is.na(x))/length(x), std = sd(x, na.rm = T) ) } )

ldply(cat_vars, function(colname) {
  x = df[,colname]
  data.frame(colname, count = length(levels(x)), levels = paste(levels(x), collapse = '|') ) } )

summary(df[, cat_vars %!in_set% non_vars])


ggplot(df, aes(logerror)) + stat_ecdf()

#con variables
#ggplot(df, aes(taxamount_pct, logerror)) + geom_point(size = 0.1 ) + geom_smooth()
#ggplot(df, aes(taxvaluedollarcnt_log, logerror)) + geom_point(size = 0.1 ) + geom_smooth()
#ggplot(df, aes(df$finishedsquarefeet12, logerror )) + geom_point(size = 0.1 ) + geom_smooth()
#ggplot(df, aes(factor(t_month),logerror)) + geom_boxplot()
#ggplot(df, aes(calculatedfinishedsquarefeet, logerror)) + geom_point(size = 0.1 ) + geom_smooth()

#removed vars
#ggplot(df, aes(factor(regionidcity),logerror)) + geom_boxplot()
#ggplot(df, aes(factor(regionidneighborhood),logerror)) + geom_boxplot()
#ggplot(df, aes(factor(regionidzip),logerror)) + geom_boxplot()
#ggplot(df, aes(factor(propertycountylandusecode),logerror)) + geom_boxplot()
#ggplot(df, aes(factor(propertyzoningdesc),logerror)) + geom_boxplot()
#ggplot(df, aes(factor(rawcensustractandblock),logerror)) + geom_boxplot()
#ggplot(df, aes(factor(storytypeid),logerror)) + geom_boxplot()
#ggplot(df, aes(logerror, group = factor(typeconstructiontypeid), color = factor(typeconstructiontypeid))) + geom_density()
#ggplot(df, aes(factor(t_year),logerror)) + geom_boxplot()
#ggplot(df, aes(taxamount,taxvaluedollarcnt)) + geom_point(size = 0.1 ) + geom_smooth()
#ggplot(df, aes(censustractandblock,logerror)) + geom_point(size = 0.1 ) + geom_smooth()
#ggplot(df, aes(longitude,logerror)) + geom_point(size = 0.1 ) + geom_smooth()

#ggplot(df, aes(t_day,logerror)) + geom_point(size = 0.1 ) + geom_smooth()
#ggplot(df, aes(factor(threequarterbathnbr),logerror)) + geom_boxplot()

#agg = ddply(df, .(parcelid), function(x) data.frame(count = length(x$parcelid), avg = mean(x$logerror), std = sd(x$logerror) ))
#filter(agg, count > 1)

ggplot_missing_count(df)

gc()
```

## Random Forest
```{r rf_model, fig.width = 8, fig.height = 6, dpi = 150, eval = FALSE, echo=TRUE}

model_rf <- foreach(ntree=rep(250, 4), .combine=combine, .multicombine=TRUE, .packages='randomForest') %dopar%
    randomForest(x = as.matrix(x.train), y = y.train, ntree=ntree, mtry = floor(ncol(x.train)/3))

prediction_rf <- predict(model_rf, x.test)
```

## GBM All
cv(5) = 0.0257
```{r gbm_all_model, fig.width = 8, fig.height = 6, dpi = 150, eval = TRUE, echo=TRUE}
start_time <- proc.time()

allvars =  unique(names(df) %!in_set% c(non_vars, nonsig_vars, fun_var))

formula.all = formula (paste( fun_var, ' ~', paste(allvars, collapse = '+')) )

num_vars = all.vars(formula.all) %in_set% names(which(sapply(df, is.numeric)))
corr_matrix = cor(df[,num_vars ], use="pairwise.complete.obs")
corrplot(corr_matrix, method="number", number.cex = 0.5, number.digits = 1)
#corrplot(corr_matrix, method="circle", number.cex = 0.5, order="hclust")

#variance inflation factors
#names(which(sapply(df, function(x) sum(is.na(x)) > nrow(df)/2)))
#sapply(df, function(x) length(levels(x)))
#ldply(cat_vars, function(x) data.frame(name =x, levels = length(levels(df[,x]))) )

model.lm = lm(formula (paste( fun_var, ' ~', paste(num_vars %!in_set% c(fun_var, names(which(sapply(df, function(x) sum(is.na(x)) > nrow(df)/2 )))), collapse = '+')) ), 
              data = df, na.action = na.exclude)
summary(model.lm)
kable(data.frame(vif(model.lm)))

print(formula.all)
print(length(allvars))

var.monotone = rep(0, length(allvars)) #1-increasing, -1 - decreasing, 0: any
#var.monotone[allvars %in% c('taxdelinquency_age')] =   1
#var.monotone[allvars %in% c('taxamount_pct')] =  -1

max_it = 60*max_it_mult #64k is for s=0.001, 

model.gbm_all = gbm(formula.all, 
                data = df[, all.vars(formula.all)], 
                distribution = 'laplace', #absolute loss - but laplace has memory leak
                n.trees = max_it,
                shrinkage = 0.001, #0.001
                bag.fraction = 0.8,
                cv.folds = 3, #5
                interaction.depth = 4,#3
                train.fraction = 1.0,
                var.monotone = var.monotone,
                par.details=gbmParallel(num_threads=4),
                #n.cores = 4,
                verbose = FALSE)

model_file = file.path(working_folder,'Zillow/gbm_model.rds')
saveRDS(model.gbm_all, model_file)
#model.gbm_all = readRDS(model_file)

#show best iteration
best_it_all = gbm.perf(model.gbm_all, method = 'cv') 
#best_it_all = max_it
print(best_it_all)
grid()
pred.gbm_all = predict(model.gbm_all, n.trees = best_it_all, newdata = df)

summary(lm(df[,fun_var] ~ pred.gbm_all))

print(paste('Mean Absolute Error: ',  mean(abs(df[,fun_var]-pred.gbm_all))))

plot_gbmiterations(model.gbm_all)

#show importance
vars.importance_all = summary(model.gbm_all, num_trees = best_it_all, plot_it=FALSE) # influence
if(is.null(vars.importance_all$rel.inf)) vars.importance_all$rel.inf = vars.importance_all$rel_inf
plot_gbminfluence(vars.importance_all[vars.importance_all$rel.inf>=inf_lowlimit,])
kable(vars.importance_all[vars.importance_all$rel.inf>=inf_lowlimit,])
kable(vars.importance_all[vars.importance_all$rel.inf< inf_lowlimit,])

imp_vars = as.character(vars.importance_all$var)[vars.importance_all$rel.inf>=inf_lowlimit]

write.csv(vars.importance_all, file.path(working_folder,'Zillow/var.importance.all.csv'))

#plot interactions
#level2_interactions = gbm3_interactions(model.gbm_all,  df[, all.vars(formula.all)], iter = best_it_all, 1, 2)
#level2_interactions = filter(level2_interactions, interaction_score>0.05)
#plot_gbminteractions(level2_interactions)
#kable(level2_interactions)

#level3_interactions = gbm_interactions(model.gbm_all,  df[, all.vars(formula.all)], iter = best_it_all, 5, 3)
#level3_interactions = filter(level3_interactions, interaction_score>0.05)
#plot_gbminteractions(level3_interactions)
#kable(level3_interactions)

plots = plot_gbm3partial(model.gbm_all, best_it_all, imp_vars, output_type = 'link')
marrangeGrob(plots, nrow=3, ncol=3)

plots = plot_gbm3partial(model.gbm_all, best_it_all, all.vars(formula.all) %!in_set% c(fun_var, imp_vars), output_type = 'link')
marrangeGrob(plots, nrow=3, ncol=3)

#plots = plot_gbmpartial_2d(model.gbm_all, best_it_all, as.character(filter(level2_interactions, interaction_score>0.1)$vars), output_type = 'link')
#marrangeGrob(plots, nrow=2, ncol=2)


plots <- llply(names(df) %in_set% imp_vars, function(vname){
  plot_result = plot_profile(pred.gbm_all, df[,fun_var], df[, vname], bucket_count = 10, min_obs = 10, error_band ='normal') + ggtitle(vname)
  return (plot_result)
})
marrangeGrob(plots, nrow=3, ncol=3)

plots <- llply(names(df) %!in_set% imp_vars, function(vname){
  plot_result = plot_profile(pred.gbm_all, df[,fun_var], df[, vname], bucket_count = 10, min_obs = 10, error_band ='normal') + ggtitle(vname)
  return (plot_result)
})
marrangeGrob(plots, nrow=3, ncol=3)

elapsed = (proc.time() - start_time)[3]
print( sprintf('elapsed: %s ( %0.1f sec | %.1f min | %.1f h)', seconds_to_period(elapsed), elapsed, elapsed/60, elapsed/(60*60)) )
gc()
```


## GBM Residual

```{r gbm_cv, fig.width = 8, fig.height = 6, dpi = 150, eval = FALSE, echo=TRUE}
start_time <- proc.time()

res_var = 'residual'
df[,res_var] = df[,fun_var] -  pred.gbm_all

res.vars =  unique(names(df) %!in_set% c(non_vars, fun_var, res_var))
formula.res = formula (paste( res_var, ' ~', paste(res.vars, collapse = '+')) )

print(formula.res)
print(length(resvars))

max_it = 10*max_it_mult #60k is for s=0.001, 

model.gbm_res = gbm(formula.res, 
                data = df[, all.vars(formula.res)], 
                distribution = 'gaussian',
                n.trees = max_it,
                shrinkage = 0.001, #0.001
                bag.fraction = 0.8,
                interaction.depth = 4,
                train.fraction = 0.8,
                n.cores = 4,
                verbose = FALSE)

best_it_res = max_it

plot_gbmiterations(model.gbm_res)

pred.gbm_res = predict(model.gbm_res, n.trees = best_it_res, newdata = df)


#show importance
vars.importance_res = summary(model.gbm_res, n.trees = best_it_res, plotit=FALSE) # influence
if(is.null(vars.importance_all$rel.inf)) vars.importance_all$rel.inf = vars.importance_all$rel_inf
plot_gbminfluence(vars.importance_res[vars.importance_res$rel.inf>=inf_lowlimit,])
kable(vars.importance_res[vars.importance_res$rel.inf>=inf_lowlimit,])
kable(vars.importance_res[vars.importance_res$rel.inf< inf_lowlimit,])

imp_vars = as.character(vars.importance_res$var)[vars.importance_res$rel.inf>=inf_lowlimit]

#plot interactions
#level2_interactions = gbm_interactions(model.gbm_res,  df[, all.vars(formula.res)], iter = best_it_res, 1, 2)
#level2_interactions = filter(level2_interactions, interaction_score>0.05)
#plot_gbminteractions(level2_interactions)
#kable(level2_interactions)

plots = plot_gbmpartial(model.gbm_res, best_it_res, imp_vars, output_type = 'link')
marrangeGrob(plots, nrow=3, ncol=3)

#plots = plot_gbmpartial_2d(model.gbm_res, best_it_res, as.character(filter(level2_interactions, interaction_score>0.1)$vars), output_type = 'link')
#marrangeGrob(plots, nrow=2, ncol=2)


plots <- llply(names(df) %in_set% imp_vars, function(vname){
  plot_result = plot_profile(pred.gbm_res, df[,res_var], df[, vname], bucket_count = 10, min_obs = 10, error_band ='normal') + ggtitle(vname)
  return (plot_result)
})
marrangeGrob(plots, nrow=3, ncol=3)


print((proc.time() - start_time)[3]/3600)
```


## Summary
```{r res_print, fig.width = 8, fig.height = 6, dpi = 150, eval = TRUE, echo=TRUE}
start_time <- proc.time()

# Solution  ---- 
predictions = predict(model.gbm_all, n.trees = best_it_all, newdata = df_test)

predictions[is.na(predictions)] = 0

ggplot(data.frame(predictions), aes(predictions)) + stat_ecdf()

summary(predictions)

df_out = mutate(select(df_test, parcelid, transactiondate), value = round(predictions,4) )
df_out = mutate(df_out, date = 100*year(transactiondate) + month(transactiondate) )
df_out <- spread(select(df_out,-transactiondate), date, value)

## print solution ---- 
submit <- rename(df_out, ParcelId = parcelid)
submit = submit[order(submit$ParcelId),]
file = file.path(working_folder, "Zillow/submission.csv")
write.csv(submit, file = file, row.names = FALSE, quote = FALSE)
zip(paste(file, '.zip', sep = ''), file, flags = "-9jX")
print(file)

elapsed = (proc.time() - start_time)[3]
print( sprintf('elapsed: %s ( %0.1f sec | %.1f min | %.1f h)', seconds_to_period(elapsed), elapsed, elapsed/60, elapsed/(60*60)) )

```
